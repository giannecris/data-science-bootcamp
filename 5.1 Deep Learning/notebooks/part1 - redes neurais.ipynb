{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nn.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dGYEB3wu01rh","colab_type":"text"},"source":["# Redes Neurais Artificiais"]},{"cell_type":"markdown","metadata":{"tags":["remove_cell"],"id":"A8ksqCDU01rj","colab_type":"text"},"source":["## Preparando os dados"]},{"cell_type":"markdown","metadata":{"id":"wRKKNfl801rk","colab_type":"text"},"source":["Vamos criar uma rede neural simples para prever *churn* de clientes. \n","\n","Vamos começar pela leitura dos dados:"]},{"cell_type":"code","metadata":{"id":"dQBGMhka01rl","colab_type":"code","colab":{}},"source":["import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8D6e8mbB01ro","colab_type":"code","colab":{}},"source":["df = pd.read_csv('Churn_Modelling.csv')\n","df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lZmlsHwT01rt","colab_type":"code","colab":{}},"source":["df['Exited'].value_counts()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"aCqt05at01rw","colab_type":"code","colab":{}},"source":["df['Geography'].value_counts()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0IyE5ePm01ry","colab_type":"code","colab":{}},"source":["df['Gender'].value_counts()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F55WS_t401r1","colab_type":"text"},"source":["Para este exemplo vamos fazer um tratamento simples dos dados, apenas convertendo as variáveis categoricas em dummies:"]},{"cell_type":"code","metadata":{"id":"oGs6BI9s01r1","colab_type":"code","colab":{}},"source":["df = pd.get_dummies(df, columns=['Geography', 'Gender'])\n","df.columns"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z_dg-Si001r5","colab_type":"text"},"source":["Vamos separar os dados de teste e treinamento:"]},{"cell_type":"code","metadata":{"id":"zyu-8JLl01r6","colab_type":"code","colab":{}},"source":["X = df[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember','EstimatedSalary', \n","        'Geography_France', 'Geography_Germany', 'Geography_Spain', 'Gender_Female']]\n","\n","y = df['Exited']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SeBizmWM01r8","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X , y, test_size = 0.1)\n","X_train, X_val, y_train, y_val = train_test_split(X , y, test_size = 0.1)\n","\n","print(X_train.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-DJrD5LK01r_","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","X_val = sc.transform(X_val)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_G1rFBZZ01sB","colab_type":"text"},"source":["## Construindo o modelo"]},{"cell_type":"markdown","metadata":{"id":"R-YJYGJs01sC","colab_type":"text"},"source":["Agora com o dados prontos vamos montar a nossa rede neural. Vamos usar a library [Keras](https://keras.io) rodando em cima do [TensorFlow](https://tensorflow.org/)\n","\n","\n","1. Definição da arquitetura\n","\n","2. Compilação\n","\n","3. Treinamento\n","\n","4. Avaliação"]},{"cell_type":"markdown","metadata":{"id":"xyW6ePju01sC","colab_type":"text"},"source":["### 1. Definição da arquitetura: \n","Definir a arquitetura da rede"]},{"cell_type":"code","metadata":{"id":"kQPVavi-01sD","colab_type":"code","colab":{}},"source":["import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.optimizers import Adam"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3vTyK8M01sF","colab_type":"code","colab":{}},"source":["def build_model():\n","    model = Sequential()\n","    \n","    # primeira camada adiciona o shape do input\n","    # adiciona a funcao de ativacao\n","    # quantidade de units (neurônios)\n","    # também é possível alterar a inicializacao, bias, entre outros -- https://keras.io/layers/core/\n","    model.add(Dense(units=10, input_dim=12, activation='relu'))\n","    model.add(Dense(10, activation='relu'))\n","    \n","    #Camada de saida com o resultado de 1 classe e a ativação sigmoid -- outras funções de ativação: https://keras.io/activations/\n","    model.add(Dense(1, activation='sigmoid'))\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dd61j62S01sI","colab_type":"text"},"source":["### Vamos entender melhor as funções de ativação:"]},{"cell_type":"markdown","metadata":{"id":"qnut6mXL01sI","colab_type":"text"},"source":["Em cada neurônio da rede há uma função de ativação, que decide se o neurônio deve ser *ativado*, e transmitir informações para a próxima camada.\n","\n","![](https://i1.wp.com/deeplearningbook.com.br/wp-content/uploads/2018/02/act.png?w=406)\n","\n","A função mais comum nas camadas intermediárias é a relu:\n","\n","![](https://cdn-images-1.medium.com/max/937/1*oePAhrm74RNnNEolprmTaQ.png)\n","\n","Na camada de saída a rede precisa nos retornar a probabilidade do cliente fazer o cancelamento.\n","\n","Por ser uma probabilidade (de 0 a 1), nós usamos a função sigmoid:\n","\n","![as vezes a função sigmóide é simplesmente representada pela curva S](https://sabedoriararefeita.files.wordpress.com/2016/02/ann_sigmoid.png?w=615)\n","\n","\n","Outras funções comuns:\n","\n","Softmax -> Usada na camada de output para problemas de multiclasse, a soma das probabilidades de todas as classes dará 1.\n","\n","elu -> para ser usada nas camadas intermediarias no lugar da relu, uma exponencial é aplicada nos valores menores que 0.\n","\n","> Em regressão não há função de ativação na camada de output\n","\n","outras funções de ativação: https://keras.io/activations/\n","explicações extras: http://deeplearningbook.com.br/funcao-de-ativacao/"]},{"cell_type":"code","metadata":{"id":"GqBxWWSX01sJ","colab_type":"code","colab":{}},"source":["model = build_model()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"R2-4sNUG01sL","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2F6w5JCt01sP","colab_type":"text"},"source":["> Podemos ver que na primeira camada 130 parâmetros (pesos) serão aprendidos ((12 inputs x 10 layers) + (1 bias * 10 layers))"]},{"cell_type":"markdown","metadata":{"id":"pGR3b2Sw01sP","colab_type":"text"},"source":["### 2. Compilar o modelo:\n","\n","Definer como a rede irá aprender. Qual o otimizador com os parâmetros de learning rate, função e parametros específicos da função e a loss function.\n"]},{"cell_type":"code","metadata":{"id":"3_XHomw-01sQ","colab_type":"code","colab":{}},"source":["# outras funções de loss: https://keras.io/losses/\n","# outros optimizers: https://keras.io/optimizers/\n","adam = Adam(lr=0.01)\n","model.compile(loss='binary_crossentropy', \n","             optimizer=adam,\n","             metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1xuR3OIU01sT","colab_type":"text"},"source":["### Vamos entender como a rede aprende:"]},{"cell_type":"markdown","metadata":{"id":"1IDh89q001sU","colab_type":"text"},"source":["Para aprender os parâmetros $w$ e $b$ é preciso uma **função de custo**. Primeiro, vamos definir uma função de perda ou $Loss Function$ de modo que quanto mais próximo da resposta certa, menor seja o valor dessa função:\n","\n","$L(\\hat{y},y)=-(y\\log{\\hat{y}} + (1-y)\\log{(1-\\hat{y})})$ (binary_crossentropy)\n","\n","> Se uma instância tem label 1, então $(1-y)$ é $0$, deixando apenas o lado esquerdo da equação. Pra que ele seja o menor possível, $\\hat{y}$ precisa ser o maior possível, no caso o mais próximo de 1. O oposto também se aplica para quando o label é 0.\n","\n","Com isso, temos a funcão de custo:\n","\n","$J(w,b)=\\frac{1}{m}\\sum_{i=1}^{m}L(\\hat{y}^i,y^i)$\n","\n","Dado nosso custo, queremos encontrar $w$ e $b$ que minimize esse custo. Para isso utilizamos o **Gradiente Descendente**. A função de custo é uma funcão convexa, como uma bacia, então o que o gradiente faz é ir descendo o mais rápido possível até chegar no fundo da bacia, no menor ponto, independente do ponto inicial.\n","\n","![enter image description here](https://blog.paperspace.com/content/images/2018/05/68747470733a2f2f707669676965722e6769746875622e696f2f6d656469612f696d672f70617274312f6772616469656e745f64657363656e742e676966.gif)\n","\n","Para fazer essa \"decida\", utilizaremos a derivada do custo e uma taxa de aprendizado ou *learning rate*, da seguinte forma:\n","\n","A cada iteração do algoritmo temos $w = w - \\alpha \\frac{\\mathrm{d}J}{\\mathrm{d}w}$, sendo $\\alpha$ o learning rate.\n","\n","De modo geral, atualizamos w e b a cada iteração, sendo a velocidade controlada pelo learning rate, até chegarmos no ponto mínimo de custo."]},{"cell_type":"markdown","metadata":{"id":"W4RwH9Jb01sV","colab_type":"text"},"source":["**Mas o que é o Adam então?**"]},{"cell_type":"markdown","metadata":{"id":"oTnbH0jp01sX","colab_type":"text"},"source":["Algoritmo de otimização da taxa de aprendizado adaptável que foi projetado especificamente para o treinamento de redes neurais profundas, pode ser usado em vez do procedimento clássico de descida de gradiente estocástico (SGD) para atualizar os pesos da rede de forma iterativa com base nos dados de treinamento.\n","\n","![](https://cdn-images-1.medium.com/max/1600/1*X9gB3l_Wh5owNPCUsaYQVQ.png)\n","\n","Mais informações: [artigo original](https://arxiv.org/abs/1412.6980), [post explicativo](https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c), [outros otimizadores](http://ruder.io/optimizing-gradient-descent/)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eKEsEXn401sX","colab_type":"text"},"source":["> **Importante**: quando estiverem fazendo experimentos com NN, testem com SGD e Adam e com diferentes **LEARNING RATES**.\n"]},{"cell_type":"markdown","metadata":{"id":"jwITCmDi01sY","colab_type":"text"},"source":["### 3. Treinamento"]},{"cell_type":"code","metadata":{"id":"RyxaBoNB01sZ","colab_type":"code","colab":{}},"source":["model.fit(x=X_train, y=y_train, validation_data=(X_val,y_val), batch_size=16, epochs=10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xhYl1kcL01sb","colab_type":"text"},"source":["> Percebemos que só com 10 épocas a rede ainda não tinha convergido, o loss ainda estava caindo, então poderíamos treinar por mais épocas!"]},{"cell_type":"markdown","metadata":{"id":"qQGY_Rjt01sb","colab_type":"text"},"source":["Temos dois parâmetros importantes no treinamento:\n","- Número de épocas: Quantas vezes a rede vai passar por todos as instâncias\n","- Tamanho do batch: Qual o tamanho do bloco que ela vai usar, ou seja, quantas instâncias por vez passarão pela rede\n"]},{"cell_type":"markdown","metadata":{"id":"kOFC_EIE01sb","colab_type":"text"},"source":["### 4. Avaliação"]},{"cell_type":"code","metadata":{"id":"usQeizWV01sc","colab_type":"code","colab":{}},"source":["y_pred = model.predict(X_test)\n","y_pred = (y_pred > 0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r67tho6C01sf","colab_type":"code","colab":{}},"source":["from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YSurd8ry01sg","colab_type":"code","colab":{}},"source":["accuracy_score(y_test, y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vtobs9R401si","colab_type":"code","colab":{}},"source":["cm = confusion_matrix(y_test, y_pred)\n","print(cm)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FIgnuVeTGKhU","colab_type":"code","colab":{}},"source":["recall_score(y_test, y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TY1vt9AyHOFE","colab_type":"code","colab":{}},"source":["precision_score(y_test, y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YMEwIDCUGnNb","colab_type":"text"},"source":["Perceba que apesar da nossa acurácia ser alta, a qualidade do modelo é ruim com baixa sensibilidade. Vamos retreinar o mesmo modelo, desta vez passando peso para as classes."]},{"cell_type":"code","metadata":{"id":"ThkZfU-KG4xS","colab_type":"code","colab":{}},"source":["model = build_model()\n","model.compile(loss='binary_crossentropy', \n","             optimizer=adam,\n","             metrics=['accuracy'])\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fEZGp8ilG45A","colab_type":"code","colab":{}},"source":["model.fit(x=X_train, y=y_train, validation_data=(X_val,y_val), batch_size=16, epochs=10, class_weight={0:0.2,1:0.8})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SMbh_RJVHcIS","colab_type":"code","colab":{}},"source":["y_pred = model.predict(X_test)\n","y_pred = (y_pred > 0.5)\n","\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MahBjtzVEJ8B","colab_type":"text"},"source":["## Exercício:\n","Crie uma nova arquitetura de rede para o mesmo dataset. Mude também o learning rate e a quantidade de épocas e compare os resultados\n"]},{"cell_type":"code","metadata":{"id":"_YaUW3OvFYv9","colab_type":"code","colab":{}},"source":["def build_model2():\n","    model = Sequential()\n","    \n","    ## TODO defina a arquitetura da rede\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-omt5xgFY3x","colab_type":"code","colab":{}},"source":["model2 = build_model2()\n","model2.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eYwBkuuBFY_f","colab_type":"code","colab":{}},"source":["## TODO defina o learning rate\n","adam = Adam(lr=      )\n","model2.compile(loss='binary_crossentropy', \n","             optimizer=adam,\n","             metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b7ghlANBFZHY","colab_type":"code","colab":{}},"source":["## TODO defina o total de épocas\n","model2.fit(x=X_train, y=y_train, validation_data=(X_val,y_val), batch_size=16, epochs=   )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ULu15NUQFZS_","colab_type":"code","colab":{}},"source":["y_pred = model2.predict(X_test)\n","y_pred = (y_pred > 0.5)\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zof3PBhF01sk","colab_type":"text"},"source":["## Por que o crescimento de Deep Learning?\n","\n","<img src=\"https://kevinzakka.github.io/assets/app_dl/perf_vs_data.png\" alt=\"drawing\" width=\"600\"/>\n","\n","Algoritmos tradicionais tendem a estabilizar a performance apartir de uma certa quantidade de dados, enquanto redes neurais tendem a ficar cada vez melhores quanto mais dados são utilizados para o aprendizado.\n","\n","Portanto, o principal motivo que faz com que as NN cresçam nos últimos anos é o grande aumento na quantidade de **dados** disponíveis.  Além disso, o poder **computacional** também é muito maior nos dias atuais, principalmente com a utilização de GPU's. O que também permitiu o desenvolvimento de **algoritmos** mais complexos e potentes.\n"]},{"cell_type":"markdown","metadata":{"id":"WfkXMpe601sl","colab_type":"text"},"source":["Neural Networks, mais especificamente Deep Learning, tem grande aplicações em datas não-estruturados, como: Imagens, Aúdios e Textos."]}]}